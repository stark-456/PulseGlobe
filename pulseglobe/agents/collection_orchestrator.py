"""
æ•°æ®é‡‡é›† Orchestrator
åè°ƒä¸‰ä¸ªé‡‡é›†å™¨è¿›è¡Œæµ·é‡æ•°æ®é‡‡é›†å¹¶å­˜å‚¨
"""
import asyncio
import logging
from datetime import datetime
from dataclasses import dataclass, field
from typing import Optional

from pulseglobe.agents.collectors import TavilyCollector, SocialCollector, RAGCollector
from pulseglobe.services.storage import PacketStorage
from pulseglobe.services.translation import TranslationService
from pulseglobe.services.summarization import SummarizationService
from pulseglobe.models.data_packet import DataPacket

logger = logging.getLogger(__name__)


@dataclass
class CollectionConfig:
    """é‡‡é›†é…ç½®"""
    # Tavily é…ç½®
    tavily_enabled: bool = True
    tavily_max_results: int = 20
    
    # Social é…ç½®
    social_enabled: bool = True
    social_platforms: list[str] = field(default_factory=lambda: ["twitter", "tiktok", "youtube"])
    social_post_count: int = 10
    social_comments_per_post: int = 10
    
    # RAG é…ç½®
    rag_enabled: bool = True
    rag_max_results: int = 15
    
    # ç¿»è¯‘é…ç½®
    translation_provider: str = "xmor"  # "xmor" æˆ– "llm"


@dataclass
class CollectionResult:
    """é‡‡é›†ç»“æœ"""
    session_id: str
    stats: dict
    duration_seconds: float


class DataCollectionOrchestrator:
    """
    æ•°æ®é‡‡é›† Orchestrator
    
    åè°ƒä¸‰ä¸ªé‡‡é›†å™¨ï¼Œæ‰§è¡Œå®Œæ•´çš„æ•°æ®é‡‡é›†æµç¨‹ï¼š
    1. è¾“å…¥ï¼šå…³é”®è¯åˆ—è¡¨ï¼ˆæ¥è‡ªé˜¶æ®µä¸€ï¼‰
    2. å¹¶è¡Œé‡‡é›†ï¼šTavily + Social + RAG
    3. ç¿»è¯‘ + æ‘˜è¦
    4. å­˜å‚¨åˆ° data_packets è¡¨
    5. è¿”å› session_id
    """
    
    def __init__(self, config: CollectionConfig = None):
        self.config = config or CollectionConfig()
        
        # å…±äº«æœåŠ¡
        self.translator = TranslationService(provider=self.config.translation_provider)
        self.summarizer = SummarizationService()
        self.storage = PacketStorage()
        
        # åˆå§‹åŒ–é‡‡é›†å™¨
        self._init_collectors()
        
        logger.info(f"[DataCollectionOrchestrator] åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"[DataCollectionOrchestrator]   Tavily: {self.config.tavily_enabled}, max={self.config.tavily_max_results}")
        logger.info(f"[DataCollectionOrchestrator]   Social: {self.config.social_enabled}, platforms={self.config.social_platforms}")
        logger.info(f"[DataCollectionOrchestrator]   RAG: {self.config.rag_enabled}, max={self.config.rag_max_results}")
    
    def _init_collectors(self):
        """åˆå§‹åŒ–é‡‡é›†å™¨"""
        self.tavily_collector = TavilyCollector(
            max_results=self.config.tavily_max_results,
            translator=self.translator,
            summarizer=self.summarizer,
        ) if self.config.tavily_enabled else None
        
        self.social_collector = SocialCollector(
            platforms=self.config.social_platforms,
            post_count=self.config.social_post_count,
            comments_per_post=self.config.social_comments_per_post,
            translator=self.translator,
            summarizer=self.summarizer,
        ) if self.config.social_enabled else None
        
        self.rag_collector = RAGCollector(
            max_results=self.config.rag_max_results,
            translator=self.translator,
            summarizer=self.summarizer,
        ) if self.config.rag_enabled else None
    
    async def collect(
        self,
        tavily_keywords: list[str],
        social_keywords: list[str],
        rag_keywords: list[str],
        session_id: str = None,
    ) -> CollectionResult:
        """
        æ‰§è¡Œæ•°æ®é‡‡é›†
        
        Args:
            tavily_keywords: Tavily æœç´¢å…³é”®è¯
            social_keywords: ç¤¾äº¤åª’ä½“å…³é”®è¯
            rag_keywords: RAG å¬å›å…³é”®è¯
            session_id: å¯é€‰çš„ä¼šè¯IDï¼Œé»˜è®¤è‡ªåŠ¨ç”Ÿæˆ
            
        Returns:
            CollectionResult åŒ…å« session_id å’Œç»Ÿè®¡ä¿¡æ¯
        """
        start_time = datetime.now()
        
        # ç”Ÿæˆ session_id
        if not session_id:
            session_id = f"sess_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        logger.info(f"{'='*70}")
        logger.info(f"[DataCollectionOrchestrator] â–¶ å¼€å§‹æ•°æ®é‡‡é›†")
        logger.info(f"[DataCollectionOrchestrator]   Session: {session_id}")
        logger.info(f"[DataCollectionOrchestrator]   Tavilyå…³é”®è¯: {len(tavily_keywords)}")
        logger.info(f"[DataCollectionOrchestrator]   Socialå…³é”®è¯: {len(social_keywords)}")
        logger.info(f"[DataCollectionOrchestrator]   RAGå…³é”®è¯: {len(rag_keywords)}")
        logger.info(f"{'='*70}")
        
        all_packets = []
        
        # é‡‡é›† Tavily æ•°æ®
        if self.tavily_collector and tavily_keywords:
            logger.info(f"\n[DataCollectionOrchestrator] ğŸ“° é‡‡é›† Tavily æ•°æ®...")
            tavily_packets = await self._collect_channel(
                collector=self.tavily_collector,
                keywords=tavily_keywords,
                keyword_type="tavily",
                session_id=session_id,
            )
            all_packets.extend(tavily_packets)
            logger.info(f"[DataCollectionOrchestrator]   Tavily é‡‡é›†å®Œæˆ: {len(tavily_packets)} æ¡")
        
        # é‡‡é›† Social æ•°æ®
        if self.social_collector and social_keywords:
            logger.info(f"\n[DataCollectionOrchestrator] ğŸ“± é‡‡é›† Social æ•°æ®...")
            social_packets = await self._collect_channel(
                collector=self.social_collector,
                keywords=social_keywords,
                keyword_type="social",
                session_id=session_id,
            )
            all_packets.extend(social_packets)
            logger.info(f"[DataCollectionOrchestrator]   Social é‡‡é›†å®Œæˆ: {len(social_packets)} æ¡")
        
        # é‡‡é›† RAG æ•°æ®
        if self.rag_collector and rag_keywords:
            logger.info(f"\n[DataCollectionOrchestrator] ğŸ“š é‡‡é›† RAG æ•°æ®...")
            rag_packets = await self._collect_channel(
                collector=self.rag_collector,
                keywords=rag_keywords,
                keyword_type="rag",
                session_id=session_id,
            )
            all_packets.extend(rag_packets)
            logger.info(f"[DataCollectionOrchestrator]   RAG é‡‡é›†å®Œæˆ: {len(rag_packets)} æ¡")
        
        # å­˜å‚¨æ•°æ®
        logger.info(f"\n[DataCollectionOrchestrator] ğŸ’¾ å­˜å‚¨æ•°æ®åŒ…...")
        save_result = self.storage.save_packets(all_packets)
        
        # è·å–ç»Ÿè®¡
        stats = self.storage.get_session_stats(session_id)
        
        duration = (datetime.now() - start_time).total_seconds()
        
        logger.info(f"\n{'='*70}")
        logger.info(f"[DataCollectionOrchestrator] â—€ é‡‡é›†å®Œæˆ")
        logger.info(f"[DataCollectionOrchestrator]   Session: {session_id}")
        logger.info(f"[DataCollectionOrchestrator]   æ€»è®¡: {stats['total']} æ¡")
        logger.info(f"[DataCollectionOrchestrator]   - Tavily: {stats.get('tavily', 0)}")
        logger.info(f"[DataCollectionOrchestrator]   - Social: {stats.get('social', 0)}")
        logger.info(f"[DataCollectionOrchestrator]   - RAG: {stats.get('rag', 0)}")
        logger.info(f"[DataCollectionOrchestrator]   æ–°å¢: {save_result['saved']}, é‡å¤: {save_result['duplicates']}")
        logger.info(f"[DataCollectionOrchestrator]   è€—æ—¶: {duration:.1f}s")
        logger.info(f"{'='*70}")
        
        return CollectionResult(
            session_id=session_id,
            stats=stats,
            duration_seconds=duration,
        )
    
    async def _collect_channel(
        self,
        collector,
        keywords: list[str],
        keyword_type: str,
        session_id: str,
    ) -> list[DataPacket]:
        """é‡‡é›†å•ä¸ªé€šé“çš„æ‰€æœ‰å…³é”®è¯"""
        all_packets = []
        
        for i, keyword in enumerate(keywords, 1):
            logger.info(f"[DataCollectionOrchestrator]   [{i}/{len(keywords)}] '{keyword}'")
            try:
                packets = await collector.collect(
                    session_id=session_id,
                    keyword=keyword,
                    keyword_type=keyword_type,
                )
                all_packets.extend(packets)
            except Exception as e:
                logger.warning(f"[DataCollectionOrchestrator]   âœ— é‡‡é›†å¤±è´¥: {e}")
                continue
        
        return all_packets
    
    def close(self):
        """å…³é—­èµ„æº"""
        if self.rag_collector:
            self.rag_collector.close()
        if hasattr(self.social_collector, 'close'):
            asyncio.create_task(self.social_collector.close())
        self.storage.close()
