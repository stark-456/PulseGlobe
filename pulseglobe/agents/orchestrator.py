"""
Orchestrator Agent
åè°ƒä¸‰ä¸ª Worker è¿›è¡Œè¿­ä»£å…³é”®è¯æ„ŸçŸ¥ï¼ˆäº¤å‰æ›´æ–°ç‰ˆæœ¬ï¼‰
ä½¿ç”¨ LangGraph å®ç°çŠ¶æ€å›¾
"""
import asyncio
import json
import logging
from typing import Literal

from langchain_core.messages import HumanMessage
from langgraph.graph import StateGraph, END

from pulseglobe.agents.state import KeywordState, OrchestratorConfig
from pulseglobe.agents.prompts import INITIAL_KEYWORD_PROMPT, SCENARIO_DESCRIPTIONS
from pulseglobe.agents.workers import TavilyWorker, RAGWorker, SocialWorker
from pulseglobe.agents.workers.base import CrossKeywordResult
from pulseglobe.services.llm import get_json_llm_client

logger = logging.getLogger(__name__)


class KeywordOrchestrator:
    """
    å…³é”®è¯æ„ŸçŸ¥ Orchestrator
    
    åè°ƒ Tavilyã€RAGã€Social ä¸‰ä¸ª Worker è¿›è¡Œè¿­ä»£å¼å…³é”®è¯å‘ç°
    æ”¯æŒäº¤å‰æ›´æ–°ï¼šæ¯ä¸ªæ¸ é“çš„ç»“æœéƒ½ä¼šæ›´æ–°ä¸‰ç±»å…³é”®è¯åˆ—è¡¨
    """
    
    def __init__(self, config: OrchestratorConfig = None):
        self.config = config or OrchestratorConfig()
        self.llm = get_json_llm_client()
        
        # åˆå§‹åŒ– Workers
        self._init_workers()
        
        # æ„å»º LangGraph
        self.graph = self._build_graph()
        
        logger.info(f"[Orchestrator] åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"[Orchestrator]   æœ€å¤§è¿­ä»£: {self.config.max_iterations}")
        logger.info(f"[Orchestrator]   æ”¶æ•›é˜ˆå€¼: {self.config.convergence_threshold}")
        logger.info(f"[Orchestrator]   Workers: tavily={self.config.tavily_enabled}, "
                   f"rag={self.config.rag_enabled}, social={self.config.social_enabled}")
    
    def _init_workers(self):
        """åˆå§‹åŒ– Worker å®ä¾‹"""
        self.tavily_worker = TavilyWorker() if self.config.tavily_enabled else None
        self.rag_worker = RAGWorker() if self.config.rag_enabled else None
        self.social_worker = SocialWorker(
            platforms=self.config.social_platforms,
            post_count=self.config.social_post_count,
            comments_per_post=self.config.social_comments_per_post,
        ) if self.config.social_enabled else None
    
    def _build_graph(self) -> StateGraph:
        """æ„å»º LangGraph çŠ¶æ€å›¾"""
        workflow = StateGraph(KeywordState)
        
        workflow.add_node("generate_initial_keywords", self._generate_initial_keywords)
        workflow.add_node("run_workers", self._run_workers)
        workflow.add_node("check_convergence", self._check_convergence)
        
        workflow.set_entry_point("generate_initial_keywords")
        
        workflow.add_edge("generate_initial_keywords", "run_workers")
        workflow.add_edge("run_workers", "check_convergence")
        
        workflow.add_conditional_edges(
            "check_convergence",
            self._should_continue,
            {"continue": "run_workers", "end": END}
        )
        
        return workflow.compile()
    
    async def run(self, country: str, query: str) -> KeywordState:
        """è¿è¡Œå…³é”®è¯æ„ŸçŸ¥æµç¨‹"""
        logger.info(f"{'='*70}")
        logger.info(f"[Orchestrator] â–¶ å¼€å§‹å…³é”®è¯æ„ŸçŸ¥")
        logger.info(f"[Orchestrator]   å›½å®¶: {country}")
        logger.info(f"[Orchestrator]   é—®é¢˜: {query}")
        logger.info(f"{'='*70}")
        
        initial_state: KeywordState = {
            "country": country,
            "query": query,
            "tavily_keywords": [],
            "social_keywords": [],
            "rag_keywords": [],
            "iteration": 0,
            "max_iterations": self.config.max_iterations,
            "converged": False,
            "iteration_stats": [],
        }
        
        final_state = await self.graph.ainvoke(initial_state)
        
        logger.info(f"{'='*70}")
        logger.info(f"[Orchestrator] â—€ å…³é”®è¯æ„ŸçŸ¥å®Œæˆ")
        logger.info(f"[Orchestrator]   è¿­ä»£æ¬¡æ•°: {final_state['iteration']}")
        logger.info(f"[Orchestrator]   Tavily ({len(final_state['tavily_keywords'])}): {final_state['tavily_keywords']}")
        logger.info(f"[Orchestrator]   Social ({len(final_state['social_keywords'])}): {final_state['social_keywords']}")
        logger.info(f"[Orchestrator]   RAG ({len(final_state['rag_keywords'])}): {final_state['rag_keywords']}")
        logger.info(f"{'='*70}")
        
        return final_state
    
    # ============ èŠ‚ç‚¹å®ç° ============
    
    async def _generate_initial_keywords(self, state: KeywordState) -> KeywordState:
        """ç”Ÿæˆåˆå§‹å…³é”®è¯"""
        logger.info(f"\n[Orchestrator] ğŸ“ ç”Ÿæˆåˆå§‹å…³é”®è¯...")
        
        country = state["country"]
        query = state["query"]
        
        tasks = []
        if self.config.tavily_enabled:
            tasks.append(self._generate_keywords_for_scenario("tavily", country, query))
        if self.config.social_enabled:
            tasks.append(self._generate_keywords_for_scenario("social", country, query))
        if self.config.rag_enabled:
            tasks.append(self._generate_keywords_for_scenario("rag", country, query))
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        idx = 0
        if self.config.tavily_enabled:
            if not isinstance(results[idx], Exception):
                state["tavily_keywords"] = results[idx]
                logger.info(f"[Orchestrator]   Tavilyåˆå§‹: {results[idx]}")
            idx += 1
        
        if self.config.social_enabled:
            if not isinstance(results[idx], Exception):
                state["social_keywords"] = results[idx]
                logger.info(f"[Orchestrator]   Socialåˆå§‹: {results[idx]}")
            idx += 1
        
        if self.config.rag_enabled:
            if not isinstance(results[idx], Exception):
                state["rag_keywords"] = results[idx]
                logger.info(f"[Orchestrator]   RAGåˆå§‹: {results[idx]}")
        
        return state
    
    async def _generate_keywords_for_scenario(
        self, scenario: str, country: str, query: str
    ) -> list[str]:
        """ä¸ºç‰¹å®šåœºæ™¯ç”Ÿæˆåˆå§‹å…³é”®è¯"""
        prompt = INITIAL_KEYWORD_PROMPT.format(
            scenario=scenario,
            country=country,
            query=query,
            scenario_description=SCENARIO_DESCRIPTIONS[scenario],
        )
        try:
            response = await self.llm.ainvoke([HumanMessage(content=prompt)])
            result = json.loads(response.content)
            return result.get("keywords", [])
        except Exception as e:
            logger.error(f"[Orchestrator] ç”Ÿæˆ{scenario}å…³é”®è¯å¤±è´¥: {e}")
            return []
    
    async def _run_workers(self, state: KeywordState) -> KeywordState:
        """å¹¶è¡Œè¿è¡Œä¸‰ä¸ª Workerï¼ˆäº¤å‰æ›´æ–°ï¼‰"""
        state["iteration"] += 1
        iteration = state["iteration"]
        
        logger.info(f"\n[Orchestrator] ğŸ”„ è¿­ä»£ {iteration}/{state['max_iterations']}")
        
        # è®°å½•è¿­ä»£å‰
        before = {
            "tavily": len(state["tavily_keywords"]),
            "social": len(state["social_keywords"]),
            "rag": len(state["rag_keywords"]),
        }
        
        # å¹¶è¡Œè¿è¡Œ Workersï¼Œä¼ å…¥æ‰€æœ‰ç°æœ‰å…³é”®è¯ç”¨äºå»é‡
        tasks = []
        worker_names = []
        
        if self.tavily_worker and state["tavily_keywords"]:
            tasks.append(self.tavily_worker.run(
                country=state["country"],
                query=state["query"],
                keywords=state["tavily_keywords"],
                tavily_keywords=state["tavily_keywords"],
                social_keywords=state["social_keywords"],
                rag_keywords=state["rag_keywords"],
            ))
            worker_names.append("tavily")
        
        if self.social_worker and state["social_keywords"]:
            tasks.append(self.social_worker.run(
                country=state["country"],
                query=state["query"],
                keywords=state["social_keywords"],
                tavily_keywords=state["tavily_keywords"],
                social_keywords=state["social_keywords"],
                rag_keywords=state["rag_keywords"],
            ))
            worker_names.append("social")
        
        if self.rag_worker and state["rag_keywords"]:
            tasks.append(self.rag_worker.run(
                country=state["country"],
                query=state["query"],
                keywords=state["rag_keywords"],
                tavily_keywords=state["tavily_keywords"],
                social_keywords=state["social_keywords"],
                rag_keywords=state["rag_keywords"],
            ))
            worker_names.append("rag")
        
        if not tasks:
            logger.warning("[Orchestrator] æ²¡æœ‰å¯è¿è¡Œçš„ Worker")
            return state
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # äº¤å‰åˆå¹¶ï¼šæ¯ä¸ª Worker çš„ç»“æœéƒ½æ›´æ–°ä¸‰ä¸ªåˆ—è¡¨
        new_counts = {"tavily": 0, "social": 0, "rag": 0}
        
        for name, result in zip(worker_names, results):
            if isinstance(result, Exception):
                logger.error(f"[Orchestrator] {name} Worker å¤±è´¥: {result}")
                continue
            
            if not isinstance(result, CrossKeywordResult):
                continue
            
            # åˆå¹¶åˆ°ä¸‰ä¸ªåˆ—è¡¨
            if result.tavily_new:
                state["tavily_keywords"] = self._merge_keywords(
                    state["tavily_keywords"], result.tavily_new
                )
                new_counts["tavily"] += len(result.tavily_new)
            
            if result.social_new:
                state["social_keywords"] = self._merge_keywords(
                    state["social_keywords"], result.social_new
                )
                new_counts["social"] += len(result.social_new)
            
            if result.rag_new:
                state["rag_keywords"] = self._merge_keywords(
                    state["rag_keywords"], result.rag_new
                )
                new_counts["rag"] += len(result.rag_new)
        
        # è®°å½•ç»Ÿè®¡
        after = {
            "tavily": len(state["tavily_keywords"]),
            "social": len(state["social_keywords"]),
            "rag": len(state["rag_keywords"]),
        }
        
        stats = {"iteration": iteration, "before": before, "after": after, "new": new_counts}
        state["iteration_stats"].append(stats)
        
        logger.info(f"[Orchestrator] ğŸ“Š è¿­ä»£ {iteration} ç»Ÿè®¡ï¼ˆäº¤å‰æ›´æ–°ï¼‰:")
        logger.info(f"[Orchestrator]   Tavily: {before['tavily']} â†’ {after['tavily']} (+{new_counts['tavily']})")
        logger.info(f"[Orchestrator]   Social: {before['social']} â†’ {after['social']} (+{new_counts['social']})")
        logger.info(f"[Orchestrator]   RAG: {before['rag']} â†’ {after['rag']} (+{new_counts['rag']})")
        
        return state
    
    async def _check_convergence(self, state: KeywordState) -> KeywordState:
        """æ£€æŸ¥æ˜¯å¦æ”¶æ•›"""
        if not state["iteration_stats"]:
            return state
        
        latest = state["iteration_stats"][-1]
        total_new = sum(latest["new"].values())
        total_current = sum(latest["after"].values())
        
        new_ratio = total_new / max(total_current, 1)
        
        if new_ratio < self.config.convergence_threshold:
            state["converged"] = True
            logger.info(f"[Orchestrator] âœ… å·²æ”¶æ•› ({new_ratio:.1%} < {self.config.convergence_threshold:.1%})")
        else:
            logger.info(f"[Orchestrator] â³ æœªæ”¶æ•› ({new_ratio:.1%} >= {self.config.convergence_threshold:.1%})")
        
        return state
    
    def _should_continue(self, state: KeywordState) -> Literal["continue", "end"]:
        if state["converged"]:
            return "end"
        if state["iteration"] >= state["max_iterations"]:
            logger.info(f"[Orchestrator] â¹ è¾¾åˆ°æœ€å¤§è¿­ä»£ {state['max_iterations']}")
            return "end"
        return "continue"
    
    def _merge_keywords(self, existing: list[str], new: list[str]) -> list[str]:
        """åˆå¹¶å…³é”®è¯ï¼ˆå­—ç¬¦ä¸²å»é‡ï¼‰"""
        seen = set()
        merged = []
        for kw in existing + new:
            kw_lower = kw.lower().strip()
            if kw_lower not in seen:
                seen.add(kw_lower)
                merged.append(kw)
        return merged[:self.config.max_keywords_per_list]
    
    def close(self):
        if self.rag_worker:
            self.rag_worker.close()
